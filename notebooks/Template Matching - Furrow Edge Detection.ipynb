{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-18T09:55:39.797376Z",
     "start_time": "2021-04-18T09:55:39.793049Z"
    }
   },
   "outputs": [],
   "source": [
    "# Move to the root\n",
    "import os\n",
    "cwd = os.getcwd()\n",
    "if os.path.basename(cwd) != \"cv-in-farming\":\n",
    "    os.chdir(\"../\")\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-18T09:55:40.510995Z",
     "start_time": "2021-04-18T09:55:40.397707Z"
    }
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-18T09:55:41.694597Z",
     "start_time": "2021-04-18T09:55:41.036618Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "from utils.helpers import create_template\n",
    "from src.dataloader import FurrowDataset\n",
    "from src.image_processing import apply_template_matching"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-18T09:55:43.594485Z",
     "start_time": "2021-04-18T09:55:43.533234Z"
    }
   },
   "outputs": [],
   "source": [
    "# Input: Enter folder holding frames on which Template Matching will be applied.\n",
    "folder = \"dataset/train/20201112_125754\"\n",
    "\n",
    "dataset_args = {\n",
    "  \"data_path\": folder,\n",
    "  \"load_edge\": True,\n",
    "  \"load_time\": False,\n",
    "}\n",
    "dataset = FurrowDataset(dataset_args)\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-30T12:30:37.997825Z",
     "start_time": "2020-11-30T12:30:37.979214Z"
    }
   },
   "source": [
    "# Apply Template Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-18T09:55:45.887085Z",
     "start_time": "2021-04-18T09:55:45.870199Z"
    }
   },
   "outputs": [],
   "source": [
    "# Input: Output path to store edge coordinates and plots. If None, results are visualized on the notebook only.\n",
    "output_path = None\n",
    "\n",
    "# Configuration of Template Matching when camera is mounted to the front.\n",
    "front_config = {\n",
    "    \"out\": output_path,\n",
    "    \"template_size\": 30,\n",
    "    \"position\": 1,\n",
    "    \"start_depth\": 0.92, # Given in depth-scale\n",
    "    \"contour_width\": 25, # Given in y-scale\n",
    "    \"y_step\": 5,         # Given in y-scale\n",
    "    \"n_contours\": 1000,\n",
    "    \"ransac_thresh\": 30,\n",
    "    \"score_thresh\": None,\n",
    "    \"roi\": [None,None,250,None], # min_y:max_y, min_x:max_x\n",
    "    \"fit_type\": \"curve\",\n",
    "    \"verbose\": 0\n",
    "}\n",
    "\n",
    "# Configuration of Template Matching when camera is mounted to the back.\n",
    "back_config = {\n",
    "    \"out\": output_path,\n",
    "    \"template_size\": 30,\n",
    "    \"position\": 2,\n",
    "    \"start_depth\": 1.10, # Given in depth-scale\n",
    "    \"contour_width\": 25, # Given in y-scale\n",
    "    \"y_step\": 5,         # Given in y-scale\n",
    "    \"n_contours\": 1000,\n",
    "    \"ransac_thresh\": 10,\n",
    "    \"score_thresh\": None,\n",
    "    \"roi\": [None,None,250,450], # min_y:max_y, min_x:max_x\n",
    "    \"fit_type\": \"curve\",\n",
    "    \"verbose\": 0\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-18T09:55:47.803096Z",
     "start_time": "2021-04-18T09:55:47.756921Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# TODO: Saving Matplotlib plots causes memory leak over time. To save plots, a different module should be used.\n",
    "# Matplotlib used to obtain scatter plots. Any alternative library for this purpose can be used.\n",
    "import gc\n",
    "\n",
    "# Given set of inliers, set of outliers, pixel coordinates for edges, prepare a plot overlaying these on depth array.\n",
    "def prepare_corner_plot(depth_arr, inliers=None, outliers=None, edge_pixels=None):\n",
    "    plt.figure(figsize=(10,10))\n",
    "    depth_arr = np.rint(255 * (depth_arr / depth_arr.max()))\n",
    "    depth_arr = np.clip(depth_arr * 7, a_min=0, a_max=255).astype(np.uint8)\n",
    "    plt.imshow(depth_arr, cmap=\"gray\")\n",
    "    if edge_pixels is not None:\n",
    "        plt.plot(edge_pixels[:,1], edge_pixels[:,0], color=\"springgreen\", linewidth=2)\n",
    "    if inliers is not None:\n",
    "        inlier_pts = plt.scatter(inliers[:,1], inliers[:,0], color=\"cyan\", marker=\"o\")\n",
    "    if outliers is not None:\n",
    "        outlier_pts = plt.scatter(outliers[:,1], outliers[:,0], color=\"red\", marker=\"x\")\n",
    "    if inliers is not None and outliers is not None:\n",
    "        plt.legend((inlier_pts, outlier_pts), (\"inliers\", \"outliers\"), loc=1)\n",
    "\n",
    "# Given pixel coordinates for edges, prepare a plot overlaying edge on RGB image.\n",
    "def prepare_overlay_plot(image, edge_pixels, cstr=\"springgreen\"):\n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.imshow(image)\n",
    "    plt.plot(edge_pixels[:,1], edge_pixels[:,0], color=cstr, linewidth=2)\n",
    "\n",
    "# Run Template Matching for a frame based on config, store the results to specified folder.\n",
    "def execute(frame_idx, depth_arr, rgb_img, \n",
    "            out,\n",
    "            template_size,\n",
    "            position,\n",
    "            start_depth,\n",
    "            contour_width,\n",
    "            y_step,\n",
    "            n_contours,\n",
    "            ransac_thresh,\n",
    "            score_thresh,\n",
    "            roi,\n",
    "            fit_type,\n",
    "            verbose):\n",
    "    \n",
    "    # Create a template to find corners\n",
    "    template = create_template(size=template_size, position=position)\n",
    "    \n",
    "    # Fit a curve (2nd degree polynomial) to inlier detections\n",
    "    edge_pixels, inliers, outliers = apply_template_matching(depth_arr,\n",
    "                                         template,\n",
    "                                         start_depth=start_depth,     # Given in depth-scale\n",
    "                                         contour_width=contour_width, # Given in y-scale\n",
    "                                         y_step=y_step,               # Given in y-scale\n",
    "                                         n_contours=n_contours,\n",
    "                                         ransac_thresh=ransac_thresh,\n",
    "                                         score_thresh=score_thresh,\n",
    "                                         roi=roi,\n",
    "                                         fit_type=fit_type,\n",
    "                                         verbose=verbose)\n",
    "    \n",
    "    # Store pixel coordinates for the edge\n",
    "    if out is not None:\n",
    "        np.save(f\"{out}/{frame_idx}_edge_pts.npy\", edge_pixels)\n",
    "      \n",
    "    # Visualize or store inlier and outlier corners and fitted curve\n",
    "    prepare_corner_plot(depth_arr, inliers, outliers, edge_pixels)\n",
    "    if out is None:\n",
    "        plt.show()\n",
    "    else:\n",
    "        plt.savefig(f\"{out}/{frame_idx}_edge_vis.png\")\n",
    "        # Clear the current axes.\n",
    "        plt.cla() \n",
    "        # Clear the current figure.\n",
    "        plt.clf() \n",
    "        # Closes all the figure windows.\n",
    "        plt.close('all')\n",
    "        gc.collect()\n",
    "\n",
    "    # Visualize or store the mask overlay on original RGB\n",
    "    prepare_overlay_plot(rgb_img, edge_pixels)\n",
    "    if out is None:\n",
    "        plt.show()\n",
    "    else:\n",
    "        plt.savefig(f\"{out}/rgb_overlay_{frame_idx}.png\")\n",
    "        # Clear the current axes.\n",
    "        plt.cla() \n",
    "        # Clear the current figure.\n",
    "        plt.clf() \n",
    "        # Closes all the figure windows.\n",
    "        plt.close('all')\n",
    "        gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execute on all frames available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-18T09:55:57.028565Z",
     "start_time": "2021-04-18T09:55:51.813972Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "load_darr = True\n",
    "load_rgb = True\n",
    "load_drgb = False\n",
    "load_edge = False\n",
    "load_time = False\n",
    "num_frames = len(dataset)\n",
    "\n",
    "for i in range(num_frames):\n",
    "    item = dataset.get_frame_files(i, \n",
    "                                   load_darr=load_darr,\n",
    "                                   load_rgb=load_rgb,\n",
    "                                   load_drgb=load_drgb,\n",
    "                                   load_edge=load_edge,\n",
    "                                   load_time=load_time)\n",
    "    frame_idx = item['frame_id']\n",
    "    rgb_img = np.array(item['rgb_img'])\n",
    "    depth_arr = item['depth_arr']\n",
    "    \n",
    "    print(f\"Detection on frame-{frame_idx}:\")\n",
    "    execute(frame_idx, depth_arr, rgb_img, **front_config)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pick one frame and execute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-18T09:55:59.071010Z",
     "start_time": "2021-04-18T09:55:59.057091Z"
    }
   },
   "outputs": [],
   "source": [
    "# Input: Use this cell to pick a desired frame or a frame at random.\n",
    "\n",
    "# Pick a frame at random:\n",
    "# num_frames = len(dataset)\n",
    "# file_indices = list(range(num_frames))\n",
    "# i = random.choice(file_indices)\n",
    "# print(\"Frame choice:\", i)\n",
    "\n",
    "# Pick a desired frame:\n",
    "i = 1287"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-18T09:55:59.655489Z",
     "start_time": "2021-04-18T09:55:59.630084Z"
    }
   },
   "outputs": [],
   "source": [
    "load_darr = True\n",
    "load_rgb = True\n",
    "load_drgb = False\n",
    "load_edge = False\n",
    "load_time = False\n",
    "item = dataset.get_frame_files(i, \n",
    "                               load_darr=load_darr,\n",
    "                               load_rgb=load_rgb,\n",
    "                               load_drgb=load_drgb,\n",
    "                               load_edge=load_edge,\n",
    "                               load_time=load_time)\n",
    "frame_idx = item['frame_id']\n",
    "rgb_img = np.array(item['rgb_img'])\n",
    "depth_arr = item['depth_arr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-18T09:56:01.398840Z",
     "start_time": "2021-04-18T09:56:01.258065Z"
    }
   },
   "outputs": [],
   "source": [
    "# Show depth array (brightness adjusted)\n",
    "plt.figure(figsize=(10,10))\n",
    "depth_arr = np.rint(255 * (depth_arr / depth_arr.max()))\n",
    "adjusted = np.clip(depth_arr * 7, a_min=0, a_max=255).astype(np.uint8)\n",
    "plt.imshow(adjusted, cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-18T09:56:01.723381Z",
     "start_time": "2021-04-18T09:56:01.577206Z"
    }
   },
   "outputs": [],
   "source": [
    "# Show cropped depth array (brightness adjusted)\n",
    "plt.figure(figsize=(10,10))\n",
    "adjusted = depth_arr[:,250:]\n",
    "adjusted = np.rint(255 * (adjusted / depth_arr.max()))\n",
    "adjusted = np.clip(adjusted * 7, a_min=0, a_max=255).astype(np.uint8)\n",
    "plt.imshow(adjusted, cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-18T09:56:04.036096Z",
     "start_time": "2021-04-18T09:56:03.368720Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(f\"Detection on frame-{frame_idx}:\")\n",
    "execute(frame_idx, depth_arr, rgb_img, **front_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Video from Existing Detections\n",
    "\n",
    "* Ready edge masks are used for overlaying. Assumes that edge masks are previously stored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-18T09:56:30.218895Z",
     "start_time": "2021-04-18T09:56:24.847871Z"
    }
   },
   "outputs": [],
   "source": [
    "from matplotlib.animation import FFMpegWriter\n",
    "\n",
    "plt.rcParams['animation.ffmpeg_path'] = '/usr/bin/ffmpeg'\n",
    "\n",
    "# Input: Folder containing RGB frames and pixel coordinates for detected edges on them.\n",
    "folder = \"dataset/train/20201112_125754\"\n",
    "# Input: Frame index range to include in the output video (a slice of 30 frames corr. to 1 sec in 30 FPS)\n",
    "frame_slice = slice(150,300)\n",
    "# Input: Name for the output video.\n",
    "output_name = \"Template Matching Demo X\"\n",
    "\n",
    "dataset_args = {\n",
    "  \"data_path\": folder,\n",
    "  \"load_edge\": True,\n",
    "  \"load_time\": False,\n",
    "}\n",
    "dataset = FurrowDataset(dataset_args)\n",
    "print(dataset)\n",
    "\n",
    "fig = plt.figure()\n",
    "\n",
    "num_frames = len(dataset)\n",
    "video_cut = list(range(num_frames))[frame_slice]\n",
    "\n",
    "metadata = dict(title=f\"{output_name}\")\n",
    "writer = FFMpegWriter(fps=30, metadata=metadata)\n",
    "\n",
    "fig = plt.figure()\n",
    "imgh = plt.imshow(np.zeros((480, 640), dtype=np.uint8))\n",
    "ph, = plt.plot([], [], color=\"cyan\", linewidth=2)\n",
    "\n",
    "load_darr = False\n",
    "load_rgb = True\n",
    "load_drgb = False\n",
    "load_edge = True\n",
    "load_time = False\n",
    "\n",
    "with writer.saving(fig, f\"{output_name}.mp4\", 100):\n",
    "    for i in video_cut:\n",
    "        item = dataset.get_frame_files(i, \n",
    "                                       load_darr=load_darr,\n",
    "                                       load_rgb=load_rgb,\n",
    "                                       load_drgb=load_drgb,\n",
    "                                       load_edge=load_edge,\n",
    "                                       load_time=load_time)\n",
    "        frame_idx = item['frame_id']\n",
    "        rgb_img = np.array(item['rgb_img'])\n",
    "        edge_pixels = item['edge_pixels']\n",
    "        \n",
    "        # Replace plot with new frame\n",
    "        imgh.set_data(rgb_img)\n",
    "        # Draw respective edge\n",
    "        ph.set_data(edge_pixels[:,1], edge_pixels[:,0])\n",
    "        \n",
    "        writer.grab_frame()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "705px",
    "left": "94px",
    "top": "110px",
    "width": "266px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "711px",
    "left": "1017px",
    "right": "20px",
    "top": "230px",
    "width": "750px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
