{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports & Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-26T13:40:54.213182Z",
     "start_time": "2021-02-26T13:40:54.207784Z"
    }
   },
   "outputs": [],
   "source": [
    "# Move to the root\n",
    "import os\n",
    "cwd = os.getcwd()\n",
    "if os.path.basename(cwd) != \"cv-in-farming\":\n",
    "    os.chdir(\"../\")\n",
    "print(\"Current directory:\", os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-26T13:41:06.027290Z",
     "start_time": "2021-02-26T13:40:54.997939Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import ConcatDataset, DataLoader\n",
    "\n",
    "from src.dataloader import FurrowDataset\n",
    "from src.model import RidgeDetector\n",
    "from src.solver import Solver, save_checkpoint, load_checkpoint\n",
    "from utils.helpers import show_image\n",
    "\n",
    "optimizers = {\n",
    "    \"adam\": torch.optim.Adam,\n",
    "    \"sgd\": torch.optim.SGD,\n",
    "    #...\n",
    "}\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-26T13:41:09.204200Z",
     "start_time": "2021-02-26T13:41:08.753297Z"
    }
   },
   "outputs": [],
   "source": [
    "# Specify input format for the network. \n",
    "# Allowed formats: darr, rgb, drgb, rgb-darr, rgb-drgb\n",
    "input_format = \"darr\"\n",
    "\n",
    "target_trans = [\"to_tensor\", \"center_crop\"]\n",
    "input_trans = target_trans + [\"normalize_imagenet\"]\n",
    "\n",
    "train_data_args0 = {\n",
    "    \"data_path\": \"dataset/train/20201112_133434\",\n",
    "    \"input_trans\": input_trans,\n",
    "    \"target_trans\": target_trans,\n",
    "    \"input_format\": input_format,\n",
    "    \"load_edge\": True,\n",
    "    \"edge_width\": 3,\n",
    "    \"load_time\": False,\n",
    "    \"start\": 0,\n",
    "    \"step\": 2,\n",
    "#     \"max_frames\": 0,\n",
    "}\n",
    "\n",
    "train_data_args1 = {\n",
    "    \"data_path\": \"dataset/train/20201112_134332\",\n",
    "    \"input_trans\": input_trans,\n",
    "    \"target_trans\": target_trans,\n",
    "    \"input_format\": input_format,\n",
    "    \"load_edge\": True,\n",
    "    \"edge_width\": 3,\n",
    "    \"load_time\": False,\n",
    "    \"start\": 0,\n",
    "    \"step\": 2,\n",
    "#     \"max_frames\": 0,\n",
    "}\n",
    "\n",
    "train_data_args2 = {\n",
    "    \"data_path\": \"dataset/train/20201112_133434_aug\",\n",
    "    \"input_trans\": input_trans,\n",
    "    \"target_trans\": target_trans,\n",
    "    \"input_format\": input_format,\n",
    "    \"load_edge\": True,\n",
    "    \"edge_width\": 3,\n",
    "    \"load_time\": False,\n",
    "    \"start\": 1,\n",
    "    \"step\": 2,\n",
    "#     \"max_frames\": np.inf,\n",
    "}\n",
    "\n",
    "train_data_args3 = {\n",
    "    \"data_path\": \"dataset/train/20201112_134332_aug\",\n",
    "    \"input_trans\": input_trans,\n",
    "    \"target_trans\": target_trans,\n",
    "    \"input_format\": input_format,\n",
    "    \"load_edge\": True,\n",
    "    \"edge_width\": 3,\n",
    "    \"load_time\": False,\n",
    "    \"start\": 1,\n",
    "    \"step\": 2,\n",
    "#     \"max_frames\": 0,\n",
    "}\n",
    "\n",
    "val_data_args = {\n",
    "    \"data_path\": \"dataset/val/20201112_125754\",\n",
    "    \"input_trans\": input_trans,\n",
    "    \"target_trans\": target_trans,\n",
    "    \"input_format\": input_format,\n",
    "    \"load_edge\": True,\n",
    "    \"edge_width\": 3,\n",
    "    \"load_time\": False,\n",
    "    \"max_frames\": 1000,\n",
    "}\n",
    "\n",
    "test_data_args = {\n",
    "    \"data_path\": \"dataset/test/20201112_140127\",\n",
    "    \"input_trans\": input_trans,\n",
    "    \"target_trans\": target_trans,\n",
    "    \"input_format\": input_format,\n",
    "    \"load_edge\": True,\n",
    "    \"edge_width\": 3,\n",
    "    \"load_time\": False,\n",
    "#     \"start\": 1500,\n",
    "#     \"end\": np.inf,\n",
    "#     \"max_frames\": 8,\n",
    "}\n",
    "\n",
    "train_dataset = ConcatDataset([\n",
    "    FurrowDataset(train_data_args0),\n",
    "    FurrowDataset(train_data_args1),\n",
    "    FurrowDataset(train_data_args2),\n",
    "    FurrowDataset(train_data_args3),\n",
    "])\n",
    "for dataset in train_dataset.datasets:\n",
    "    print(dataset)\n",
    "print(f\"Train total: {len(train_dataset)}\\n\")\n",
    "\n",
    "val_dataset = FurrowDataset(val_data_args)\n",
    "print(val_dataset)\n",
    "\n",
    "# test_dataset = FurrowDataset(test_data_args)\n",
    "# print(test_dataset)\n",
    "\n",
    "# train_dataset.save_args(\"checkpoint/train_data_args\")\n",
    "# val_dataset.save_args(\"checkpoint/val_data_args\")\n",
    "# test_dataset.save_args(\"checkpoint/test_data_args\")\n",
    "\n",
    "# Perhaps can be useful later on:\n",
    "# shuffled = np.random.permutation(train_dataset.frame_ids)\n",
    "# 80-10-10\n",
    "# train, val, test = np.split(shuffled, [int(len(shuffled)*0.8), int(len(shuffled)*0.9)])\n",
    "# train_dataset.frame_ids = sorted(train)\n",
    "# val_dataset.frame_ids = sorted(val)\n",
    "# test_dataset.frame_ids = sorted(test)\n",
    "# print(train_dataset)\n",
    "# print(val_dataset)\n",
    "# print(test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-26T14:01:55.287970Z",
     "start_time": "2021-02-26T14:01:55.269283Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train_sample = train_dataset.datasets[0].get_frame_files(0, load_darr=True, load_rgb=False, load_drgb=False, load_edge=False, load_time=False)\n",
    "val_sample = val_dataset.get_frame_files(0, load_darr=True, load_rgb=False, load_drgb=False, load_edge=False, load_time=False)\n",
    "\n",
    "print(train_sample[\"depth_arr\"].max())\n",
    "# print(train_sample[\"depth_arr\"][-1])\n",
    "\n",
    "print(val_sample[\"depth_arr\"].max())\n",
    "# print(val_sample[\"depth_arr\"][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-21T19:54:24.134587Z",
     "start_time": "2021-02-21T19:54:24.115790Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i, dataset in enumerate(train_dataset.datasets):\n",
    "    print(f\"Dataset-{i}:\")\n",
    "    print(dataset.frame_ids)\n",
    "    print(dataset.augs)\n",
    "# print(\"Validation:\", val_rgb_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-01T20:19:35.030742Z",
     "start_time": "2021-02-01T20:19:34.630672Z"
    }
   },
   "outputs": [],
   "source": [
    "from utils.helpers import show_image, show_image_pairs, coord_to_mask\n",
    "rand_idx = np.random.randint(0, 100)\n",
    "item = train_dataset.__getitem__(rand_idx)\n",
    "print(item)\n",
    "frame_id = item[\"frame_id\"]\n",
    "\n",
    "print(f\"Random Index: {rand_idx} <-> Frame ID: {frame_id}\")\n",
    "\n",
    "shape = (480, 640)\n",
    "if train_data_args[\"load_darr\"]:\n",
    "    depth_arr = np.array(item['depth_arr'])\n",
    "    print(f\"Depth array shape: {depth_arr.shape}\")\n",
    "\n",
    "if train_data_args[\"load_edge\"]:\n",
    "    edge_mask = item['edge_mask']\n",
    "    show_image(edge_mask.permute(1,2,0), cmap=\"gray\")\n",
    "\n",
    "if train_data_args[\"load_rgb\"]:\n",
    "    rgb_img = item['rgb_img']\n",
    "    show_image(rgb_img.permute(1,2,0))\n",
    "\n",
    "if train_data_args[\"load_drgb\"]:\n",
    "    depth_img = item['depth_img']\n",
    "    show_image(depth_img.permute(1,2,0))\n",
    "\n",
    "if train_data_args[\"load_time\"]:\n",
    "    time = np.array(item['time'])\n",
    "    print(f\"Timestamp: {time}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model & Optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create New Model & Optimizer Instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-22T10:38:03.912932Z",
     "start_time": "2021-02-22T10:38:01.859824Z"
    }
   },
   "outputs": [],
   "source": [
    "model_args = {\n",
    "    \"pretrained\": False,\n",
    "    \"input_format\": input_format\n",
    "}\n",
    "\n",
    "adam_args = {\n",
    "    \"lr\": 0.001,\n",
    "    \"betas\": (0.9, 0.999),\n",
    "    \"eps\": 1e-08,\n",
    "    \"weight_decay\": 0,\n",
    "    \"amsgrad\": False,\n",
    "}\n",
    "\n",
    "sgd_args = {\n",
    "     \"lr\": 0.1, \n",
    "    \"momentum\": 0.9\n",
    "}\n",
    "\n",
    "model = RidgeDetector(model_args)\n",
    "optim = optimizers['adam'](filter(lambda p: p.requires_grad, model.parameters()), **adam_args)\n",
    "\n",
    "print(model)\n",
    "print(optim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Load Stored Model & Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-11T10:04:30.500395Z",
     "start_time": "2021-02-11T10:04:11.935710Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "epoch = 6\n",
    "ckpt_path = f\"checkpoint/{epoch}_ckpt.pth\"\n",
    "last_epoch, last_loss, last_acc, model, optim = load_checkpoint(ckpt_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Load Original HED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-04T21:59:32.133446Z",
     "start_time": "2021-02-04T21:59:30.501852Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_args = {\n",
    "    \"pretrained\": False,\n",
    "    \"fuse\": True,\n",
    "}\n",
    "weight_map = {\n",
    " 'stage1.0.weight':'moduleVggOne.0.weight',\n",
    " 'stage1.0.bias': 'moduleVggOne.0.bias',\n",
    " 'stage1.2.weight': 'moduleVggOne.2.weight',\n",
    " 'stage1.2.bias': 'moduleVggOne.2.bias',\n",
    " 'sideout1.0.weight': 'moduleScoreOne.weight',\n",
    " 'sideout1.0.bias': 'moduleScoreOne.bias',\n",
    " 'stage2.5.weight':  'moduleVggTwo.1.weight',\n",
    " 'stage2.5.bias':  'moduleVggTwo.1.bias',\n",
    " 'stage2.7.weight':  'moduleVggTwo.3.weight',\n",
    " 'stage2.7.bias':  'moduleVggTwo.3.bias',\n",
    " 'sideout2.0.weight':  'moduleScoreTwo.weight',\n",
    " 'sideout2.0.bias':  'moduleScoreTwo.bias',\n",
    " 'stage3.10.weight':  'moduleVggThr.1.weight',\n",
    " 'stage3.10.bias':  'moduleVggThr.1.bias',\n",
    " 'stage3.12.weight':  'moduleVggThr.3.weight',\n",
    " 'stage3.12.bias':  'moduleVggThr.3.bias',\n",
    " 'stage3.14.weight':  'moduleVggThr.5.weight',\n",
    " 'stage3.14.bias':  'moduleVggThr.5.bias',\n",
    " 'sideout3.0.weight':  'moduleScoreThr.weight',\n",
    " 'sideout3.0.bias':  'moduleScoreThr.bias',\n",
    " 'stage4.17.weight':  'moduleVggFou.1.weight',\n",
    " 'stage4.17.bias':  'moduleVggFou.1.bias',\n",
    " 'stage4.19.weight':  'moduleVggFou.3.weight',\n",
    " 'stage4.19.bias':  'moduleVggFou.3.bias',\n",
    " 'stage4.21.weight':  'moduleVggFou.5.weight',\n",
    " 'stage4.21.bias':  'moduleVggFou.5.bias',\n",
    " 'sideout4.0.weight':  'moduleScoreFou.weight',\n",
    " 'sideout4.0.bias':  'moduleScoreFou.bias',\n",
    " 'stage5.24.weight':  'moduleVggFiv.1.weight',\n",
    " 'stage5.24.bias':  'moduleVggFiv.1.bias',\n",
    " 'stage5.26.weight':  'moduleVggFiv.3.weight',\n",
    " 'stage5.26.bias':  'moduleVggFiv.3.bias',\n",
    " 'stage5.28.weight':  'moduleVggFiv.5.weight',\n",
    " 'stage5.28.bias':  'moduleVggFiv.5.bias',\n",
    " 'sideout5.0.weight':  'moduleScoreFiv.weight',\n",
    " 'sideout5.0.bias':  'moduleScoreFiv.bias',\n",
    " 'fuse.weight': 'moduleCombine.0.weight',\n",
    " 'fuse.bias': 'moduleCombine.0.bias',\n",
    "}\n",
    "\n",
    "ckpt_path = \"checkpoint/network-bsds500.pytorch\"\n",
    "checkpoint = torch.load(ckpt_path)\n",
    "\n",
    "model = RidgeDetector(model_args)\n",
    "\n",
    "state = {}\n",
    "for k1 in model.state_dict().keys():\n",
    "    k2 = weight_map[k1]\n",
    "    state[k1] = checkpoint[k2]\n",
    "    \n",
    "model.load_state_dict(state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-22T10:38:11.085328Z",
     "start_time": "2021-02-22T10:38:11.009869Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "run_id = 0\n",
    "old_runs = list(filter(lambda x: 'run' in x, os.listdir(\"log/\")))\n",
    "if old_runs:\n",
    "    run_id = int(max(old_runs).split('run')[-1]) + 1\n",
    "solver_args = {\n",
    "    \"device\": torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\"),\n",
    "    \"loss_func\": \"class_balanced_bce\",\n",
    "    \"metric_func\": \"f1\",\n",
    "    \"log_path\": f\"log/run{run_id}/\",\n",
    "}\n",
    "\n",
    "solver = Solver(solver_args)\n",
    "\n",
    "print(solver)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-30T12:30:37.997825Z",
     "start_time": "2020-11-30T12:30:37.979214Z"
    }
   },
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-22T10:38:16.584817Z",
     "start_time": "2021-02-22T10:38:16.568065Z"
    }
   },
   "outputs": [],
   "source": [
    "batch_size = 20 # TODO: 24\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "print(f\"Total train iterations (batch count): {len(train_loader)}\")\n",
    "print(f\"Total validation iterations (batch count): {len(val_loader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-22T11:37:17.584940Z",
     "start_time": "2021-02-22T10:38:51.439704Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# TODO: Separate args for val and train logging.\n",
    "train_args = {\n",
    "    \"ckpt_path\": \"checkpoint\",\n",
    "    \"max_epochs\": 20,\n",
    "    \"ckpt_freq\": 5,       # in epochs\n",
    "    \"train_log_freq\": 10,  # in iterations\n",
    "    \"train_vis_freq\": 50, # in iterations\n",
    "    \"val_freq\": 1,      # in epochs\n",
    "    \"val_log_freq\": 5, # in iterations\n",
    "    \"val_vis_freq\": 10, # in iterations\n",
    "    \"max_vis\": 5,       # Number of rows in tensorboard image log\n",
    "    \"input_format\": input_format,\n",
    "}\n",
    "solver.train(model, optim, train_loader, val_loader, train_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-21T20:31:34.022646Z",
     "start_time": "2021-02-21T20:31:33.949443Z"
    }
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-01T20:24:52.108568Z",
     "start_time": "2021-02-01T20:24:51.847257Z"
    }
   },
   "outputs": [],
   "source": [
    "save_checkpoint(train_args['ckpt_path'], 1, model, optim, loss=None, acc=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-04T22:39:28.650116Z",
     "start_time": "2021-02-04T22:39:28.632169Z"
    }
   },
   "outputs": [],
   "source": [
    "test_args = {\n",
    "    \"input_format\": \"darr\",\n",
    "}\n",
    "\n",
    "batch_size = 8\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "print(f\"Total test iterations (batch count): {len(test_loader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-04T22:39:31.077465Z",
     "start_time": "2021-02-04T22:39:29.967534Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results = solver.test(model, test_loader, test_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unit Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-11T10:18:17.553247Z",
     "start_time": "2021-02-11T10:18:16.225012Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from torchvision.transforms import functional as F\n",
    "from utils.helpers import show_image\n",
    "\n",
    "# TODO: Refactor here\n",
    "def detect(model, image):\n",
    "    model.eval()\n",
    "    X = F.to_tensor(image).unsqueeze(0)\n",
    "    X = F.normalize(X, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    logits = model(X)\n",
    "    logits = logits.squeeze(0)\n",
    "    preds = torch.sigmoid(logits)\n",
    "    print(torch.all(torch.isclose(torch.zeros(1), preds[0])))\n",
    "    print(torch.all(torch.isclose(torch.zeros(1), preds[1])))\n",
    "    print(torch.all(torch.isclose(torch.zeros(1), preds[2])))\n",
    "    print(torch.all(torch.isclose(torch.zeros(1), preds[3])))\n",
    "    print(torch.all(torch.isclose(torch.zeros(1), preds[4])))\n",
    "    print(torch.all(torch.isclose(torch.zeros(1), preds[5])))\n",
    "    pred0 = F.to_pil_image(preds[0])\n",
    "    pred1 = F.to_pil_image(preds[1])\n",
    "    pred2 = F.to_pil_image(preds[2])\n",
    "    pred3 = F.to_pil_image(preds[3])\n",
    "    pred4 = F.to_pil_image(preds[4])\n",
    "    pred5 = F.to_pil_image(preds[5])\n",
    "    pred6 = F.to_pil_image(preds.mean(dim=0, keepdims=True))\n",
    "    return pred0, pred1, pred2, pred3, pred4, pred5, pred6\n",
    "\n",
    "# path = './dataset/20201112_125754/5032_depth.npy'\n",
    "# depth_arr = np.load(path)\n",
    "# depth_arr = np.rint(255 * (depth_arr / depth_arr.max())).astype(np.uint8)\n",
    "# depth_arr = np.stack([depth_arr, depth_arr, depth_arr], axis=-1)\n",
    "# image = Image.open(path)\n",
    "zeros = np.zeros((480,640,3), dtype=np.uint8)\n",
    "detections = detect(model, zeros)\n",
    "for detection in detections:\n",
    "    show_image(detection, cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Video from Frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-21T19:30:22.486835Z",
     "start_time": "2021-01-21T19:30:11.920196Z"
    }
   },
   "outputs": [],
   "source": [
    "from matplotlib.animation import FFMpegWriter\n",
    "\n",
    "plt.rcParams['animation.ffmpeg_path'] = '/usr/bin/ffmpeg'\n",
    "\n",
    "folder = \"front(20201112_140127)\"\n",
    "fig = plt.figure()\n",
    "cut = folder_frame_map[folder][150:450]\n",
    "\n",
    "# Fixing random state for reproducibility\n",
    "metadata = dict(title='Detection Demo')\n",
    "writer = FFMpegWriter(fps=30, metadata=metadata)\n",
    "\n",
    "fig = plt.figure()\n",
    "imgh = plt.imshow(np.zeros((480, 640), dtype=np.uint8))\n",
    "ph, = plt.plot([], [], color=\"cyan\", linewidth=2)\n",
    "\n",
    "with writer.saving(fig, \"Detection Demo.mp4\", 100):\n",
    "    for rgb_im_file, depth_arr_file, depth_im_file in cut:\n",
    "        frame_idx = rgb_im_file.split(\"_\")[0]\n",
    "\n",
    "        rgb_im_path = os.path.join(folder, rgb_im_file)\n",
    "        rgb_img = cv2.imread(rgb_im_path, cv2.IMREAD_COLOR)\n",
    "        edge_pixels = np.load(os.path.join(folder, f\"{frame_idx}_edge_pts.npy\"))\n",
    "        \n",
    "        imgh.set_data(rgb_img)\n",
    "        ph.set_data(edge_pixels[:,1], edge_pixels[:,0])\n",
    "        \n",
    "        writer.grab_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "705px",
    "left": "94px",
    "top": "110px",
    "width": "266px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "711px",
    "left": "1017px",
    "right": "20px",
    "top": "230px",
    "width": "750px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
