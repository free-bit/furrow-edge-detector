{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-24T21:40:04.988193Z",
     "start_time": "2021-03-24T21:40:04.984353Z"
    }
   },
   "outputs": [],
   "source": [
    "# Move to the root\n",
    "import os\n",
    "cwd = os.getcwd()\n",
    "if os.path.basename(cwd) != \"cv-in-farming\":\n",
    "    os.chdir(\"../\")\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-24T21:40:05.454831Z",
     "start_time": "2021-03-24T21:40:05.302813Z"
    }
   },
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "import random\n",
    "\n",
    "from matplotlib import colors\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Utility Functions \n",
    "\n",
    "Importing from [helpers.py](../utils/helpers.py)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-24T21:40:06.011856Z",
     "start_time": "2021-03-24T21:40:05.606670Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "from utils.helpers import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Image Processing Functions\n",
    "\n",
    "Importing from [image_processing.py](../src/image_processing.py)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-24T21:40:06.777062Z",
     "start_time": "2021-03-24T21:40:06.144746Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "from src.image_processing import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-24T21:40:15.177576Z",
     "start_time": "2021-03-24T21:40:15.070946Z"
    }
   },
   "outputs": [],
   "source": [
    "folders = [\"test_data/complete/20210309_140832\"] # os.listdir(dataset)\n",
    "\n",
    "# folder_frame_map: Dict of folders -> Dict of frames -> (RGB, D-RGB, ndarray)\n",
    "folder_frame_map = OrderedDict()\n",
    "\n",
    "for folder in folders:\n",
    "    files = os.listdir(folder)\n",
    "    \n",
    "    rgb_im_files = []\n",
    "    depth_arr_files = []\n",
    "    depth_im_files = []\n",
    "    timestamps = []\n",
    "    \n",
    "    # Filter files wrt their extension\n",
    "    for file in files:\n",
    "        if file.endswith(\"rgb.png\"):\n",
    "            rgb_im_files.append(file)\n",
    "        elif file.endswith(\"depth.npy\"):\n",
    "            depth_arr_files.append(file)\n",
    "        elif file.endswith(\"depth.png\"):\n",
    "            depth_im_files.append(file)\n",
    "        elif file.endswith(\".json\"):\n",
    "            timestamps.append(file)\n",
    "        elif file.endswith(\"edge_vis.png\"):\n",
    "            pass\n",
    "        elif file.endswith(\"edge_pts.npy\"):\n",
    "            pass\n",
    "        else:\n",
    "            raise AssertionError(f\"Unrecognized file: {file}\")\n",
    "            \n",
    "    rgb_im_files = sorted(rgb_im_files, key=lambda f: int(f.split(\"_\")[0]))\n",
    "    depth_arr_files = sorted(depth_arr_files, key=lambda f: int(f.split(\"_\")[0]))\n",
    "    #depth_im_files = sorted(depth_im_files, key=lambda f: int(f.split(\"_\")[0]))\n",
    "    #folder_frame_map[folder] = list(zip(rgb_im_files, depth_arr_files, depth_im_files))\n",
    "    folder_frame_map[folder] = list(zip(rgb_im_files, depth_arr_files))\n",
    "    \n",
    "print(\"Number of folders:\", len(folder_frame_map))\n",
    "for i, k in enumerate(folders):\n",
    "    print(\"{}) Loaded {} frames from {}\".format(i+1, len(folder_frame_map[folder]), k))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-30T12:30:37.997825Z",
     "start_time": "2020-11-30T12:30:37.979214Z"
    }
   },
   "source": [
    "# Detect Corners & Edge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-15T15:59:31.153594Z",
     "start_time": "2021-03-15T15:59:31.134285Z"
    }
   },
   "outputs": [],
   "source": [
    "front_config = {\n",
    "    \"out\": \"test_data/complete/20210309_140832_detections\",\n",
    "    \"template_size\": 30,\n",
    "    \"position\": 1,\n",
    "    \"start_depth\": 0.92,  # Given in depth-scale\n",
    "    \"contour_width\": 25, # Given in y-scale\n",
    "    \"y_step\": 5,         # Given in y-scale\n",
    "    \"n_contours\": 1000,\n",
    "    \"ransac_thresh\": 30, #15\n",
    "    \"score_thresh\": None,\n",
    "    \"roi\": [None,None,250,None], # min_y:max_y, min_x:max_x\n",
    "    \"fit_type\": \"curve\",\n",
    "    \"verbose\": 0\n",
    "}\n",
    "\n",
    "back_config = {\n",
    "    \"out\": None,\n",
    "    \"template_size\": 30,\n",
    "    \"position\": 2,\n",
    "    \"start_depth\": 1.10,  # Given in depth-scale\n",
    "    \"contour_width\": 25, # Given in y-scale\n",
    "    \"y_step\": 5,         # Given in y-scale\n",
    "    \"n_contours\": 1000,\n",
    "    \"ransac_thresh\": 10,\n",
    "    \"score_thresh\": None,\n",
    "    \"roi\": [None,None,250,450], # min_y:max_y, min_x:max_x\n",
    "    \"fit_type\": \"curve\",\n",
    "    \"verbose\": 0\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-15T15:59:33.218943Z",
     "start_time": "2021-03-15T15:59:33.162609Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "def prepare_corner_plot(depth_arr, inliers=None, outliers=None, edge_pixels=None):\n",
    "    plt.figure(figsize=(10,10))\n",
    "    depth_arr = np.rint(255 * (depth_arr / depth_arr.max()))\n",
    "    depth_arr = np.clip(depth_arr * 7, a_min=0, a_max=255).astype(np.uint8)\n",
    "    plt.imshow(depth_arr, cmap=\"gray\")\n",
    "    if edge_pixels is not None:\n",
    "        plt.plot(edge_pixels[:,1], edge_pixels[:,0], color=\"springgreen\", linewidth=2)\n",
    "    if inliers is not None:\n",
    "        inlier_pts = plt.scatter(inliers[:,1], inliers[:,0], color=\"cyan\", marker=\"o\")\n",
    "    if outliers is not None:\n",
    "        outlier_pts = plt.scatter(outliers[:,1], outliers[:,0], color=\"red\", marker=\"x\")\n",
    "    if inliers is not None and outliers is not None:\n",
    "        plt.legend((inlier_pts, outlier_pts), (\"inliers\", \"outliers\"), loc=1)\n",
    "    \n",
    "def prepare_overlay_plot(image, edge_pixels, cstr=\"springgreen\"):\n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.imshow(image)\n",
    "    plt.plot(edge_pixels[:,1], edge_pixels[:,0], color=cstr, linewidth=2)\n",
    "\n",
    "def execute(frame_idx, depth_arr, rgb_img, \n",
    "            out,\n",
    "            template_size,\n",
    "            position,\n",
    "            start_depth,\n",
    "            contour_width,\n",
    "            y_step,\n",
    "            n_contours,\n",
    "            ransac_thresh,\n",
    "            score_thresh,\n",
    "            roi,\n",
    "            fit_type,\n",
    "            verbose):\n",
    "    \n",
    "    # Create a template to find corners\n",
    "    template = create_template(size=template_size, position=position)\n",
    "    \n",
    "    # Fit a curve (2nd degree polynomial) to inlier detections\n",
    "    edge_pixels, inliers, outliers = apply_template_matching(depth_arr,\n",
    "                                         template,\n",
    "                                         start_depth=start_depth,     # Given in depth-scale\n",
    "                                         contour_width=contour_width, # Given in y-scale\n",
    "                                         y_step=y_step,               # Given in y-scale\n",
    "                                         n_contours=n_contours,\n",
    "                                         ransac_thresh=ransac_thresh,\n",
    "                                         score_thresh=score_thresh,\n",
    "                                         roi=roi,\n",
    "                                         fit_type=fit_type,\n",
    "                                         verbose=verbose)\n",
    "    \n",
    "    # Store pixel coordinates for the edge\n",
    "    if out is not None:\n",
    "        np.save(f\"{out}/{frame_idx}_edge_pts.npy\", edge_pixels)\n",
    "        \n",
    "    # Visualize or store inlier and outlier corners\n",
    "#     prepare_corner_plot(depth_arr, inliers, outliers)\n",
    "#     if out is None:\n",
    "#         plt.show()\n",
    "        \n",
    "    # Visualize or store fitted curve\n",
    "#     prepare_corner_plot(depth_arr, edge_pixels=edge_pixels)\n",
    "#     if out is None:\n",
    "#         plt.show()\n",
    "      \n",
    "    # Visualize or store inlier and outlier corners and fitted curve\n",
    "    prepare_corner_plot(depth_arr, inliers, outliers, edge_pixels)\n",
    "    if out is None:\n",
    "        plt.show()\n",
    "    else:\n",
    "        plt.savefig(f\"{out}/{frame_idx}_edge_vis.png\")\n",
    "        # Clear the current axes.\n",
    "        plt.cla() \n",
    "        # Clear the current figure.\n",
    "        plt.clf() \n",
    "        # Closes all the figure windows.\n",
    "        plt.close('all')\n",
    "        gc.collect()\n",
    "\n",
    "    # Visualize or store the mask overlay on original RGB\n",
    "#     prepare_overlay_plot(rgb_img, edge_pixels)\n",
    "#     if out is None:\n",
    "#         plt.show()\n",
    "#     else:\n",
    "#         plt.savefig(f\"{out}/rgb_overlay_{frame_idx}.png\")\n",
    "#         # Clear the current axes.\n",
    "#         plt.cla() \n",
    "#         # Clear the current figure.\n",
    "#         plt.clf() \n",
    "#         # Closes all the figure windows.\n",
    "#         plt.close('all')\n",
    "#         gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execute on all frames available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-15T16:51:56.355949Z",
     "start_time": "2021-03-15T15:59:50.633783Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "folder = folders[0]\n",
    "num_frames = len(folder_frame_map[folder])\n",
    "x = list(range(num_frames))\n",
    "# x = x[::400]\n",
    "for i in x:\n",
    "    #rgb_im_file, depth_arr_file, depth_im_file = folder_frame_map[folder][i]\n",
    "    rgb_im_file, depth_arr_file = folder_frame_map[folder][i]\n",
    "    frame_idx = rgb_im_file.split(\"_\")[0]\n",
    "    print(f\"Detection on frame-{frame_idx}:\")\n",
    "    \n",
    "    rgb_im_path = os.path.join(folder, rgb_im_file)\n",
    "    #depth_im_path = os.path.join(folder, depth_im_file)\n",
    "    depth_arr_path = os.path.join(folder, depth_arr_file)\n",
    "\n",
    "    rgb_img = cv2.imread(rgb_im_path, cv2.IMREAD_COLOR)     # BGR image\n",
    "    #depth_img = cv2.imread(depth_im_path, cv2.IMREAD_COLOR) # BGR image\n",
    "    depth_arr = np.load(depth_arr_path)\n",
    "    \n",
    "    execute(frame_idx, depth_arr, rgb_img, **front_config)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pick one frame and execute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-15T11:59:26.115993Z",
     "start_time": "2021-03-15T11:59:11.831076Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# folder_indices = list(range(8))\n",
    "# folder_idx = random.choice(folder_indices)\n",
    "# print(\"Folder choice:\", folder_idx)\n",
    "folder_idx = 0\n",
    "folder = folders[folder_idx]\n",
    "\n",
    "# file_indices = list(range(len(folder_frame_map[folder])))\n",
    "# i = random.choice(file_indices)\n",
    "# print(\"Frame choice:\", i)\n",
    "i = 1287\n",
    "print(\"Fetching frame: {} from folder: {}\".format(i, folder))\n",
    "\n",
    "rgb_im_file, depth_arr_file, depth_im_file = folder_frame_map[folder][i]\n",
    "frame_idx = rgb_im_file.split(\"_\")[0]\n",
    "print(f\"Detection on frame-{frame_idx}:\")\n",
    "\n",
    "rgb_im_path = os.path.join(folder, rgb_im_file)\n",
    "depth_im_path = os.path.join(folder, depth_im_file)\n",
    "depth_arr_path = os.path.join(folder, depth_arr_file)\n",
    "\n",
    "rgb_img = cv2.imread(rgb_im_path, cv2.IMREAD_COLOR)     # BGR image\n",
    "depth_img = cv2.imread(depth_im_path, cv2.IMREAD_COLOR) # BGR image\n",
    "depth_arr = np.load(depth_arr_path)\n",
    "\n",
    "execute(frame_idx, depth_arr, rgb_img, depth_img, **front_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-14T14:37:35.626224Z",
     "start_time": "2021-03-14T14:37:35.460968Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "depth_arr = np.rint(255 * (depth_arr / depth_arr.max()))\n",
    "adjusted = np.clip(depth_arr * 7, a_min=0, a_max=255).astype(np.uint8)\n",
    "plt.imshow(adjusted, cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-14T14:37:37.695144Z",
     "start_time": "2021-03-14T14:37:37.549141Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "adjusted = depth_arr[:,250:]\n",
    "adjusted = np.rint(255 * (adjusted / depth_arr.max()))\n",
    "adjusted = np.clip(adjusted * 7, a_min=0, a_max=255).astype(np.uint8)\n",
    "plt.imshow(adjusted, cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Video from Frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-21T19:30:22.486835Z",
     "start_time": "2021-01-21T19:30:11.920196Z"
    }
   },
   "outputs": [],
   "source": [
    "from matplotlib.animation import FFMpegWriter\n",
    "\n",
    "plt.rcParams['animation.ffmpeg_path'] = '/usr/bin/ffmpeg'\n",
    "\n",
    "folder = \"front(20201112_140127)\"\n",
    "fig = plt.figure()\n",
    "cut = folder_frame_map[folder][150:450]\n",
    "\n",
    "# Fixing random state for reproducibility\n",
    "metadata = dict(title='Detection Demo')\n",
    "writer = FFMpegWriter(fps=30, metadata=metadata)\n",
    "\n",
    "fig = plt.figure()\n",
    "imgh = plt.imshow(np.zeros((480, 640), dtype=np.uint8))\n",
    "ph, = plt.plot([], [], color=\"cyan\", linewidth=2)\n",
    "\n",
    "with writer.saving(fig, \"Detection Demo.mp4\", 100):\n",
    "    for rgb_im_file, depth_arr_file, depth_im_file in cut:\n",
    "        frame_idx = rgb_im_file.split(\"_\")[0]\n",
    "\n",
    "        rgb_im_path = os.path.join(folder, rgb_im_file)\n",
    "        rgb_img = cv2.imread(rgb_im_path, cv2.IMREAD_COLOR)\n",
    "        edge_pixels = np.load(os.path.join(folder, f\"{frame_idx}_edge_pts.npy\"))\n",
    "        \n",
    "        imgh.set_data(rgb_img)\n",
    "        ph.set_data(edge_pixels[:,1], edge_pixels[:,0])\n",
    "        \n",
    "        writer.grab_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "705px",
    "left": "94px",
    "top": "110px",
    "width": "266px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "711px",
    "left": "1017px",
    "right": "20px",
    "top": "230px",
    "width": "750px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
