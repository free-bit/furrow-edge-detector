{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-26T16:18:14.587611Z",
     "start_time": "2021-01-26T16:18:14.583352Z"
    }
   },
   "outputs": [],
   "source": [
    "# Move to the root\n",
    "import os\n",
    "cwd = os.getcwd()\n",
    "if os.path.basename(cwd) != \"cv-in-farming\":\n",
    "    os.chdir(\"../\")\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-26T16:18:15.640040Z",
     "start_time": "2021-01-26T16:18:15.501989Z"
    }
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import os\n",
    "import time\n",
    "\n",
    "import matplotlib\n",
    "\n",
    "from ipywidgets import *\n",
    "from IPython.display import display\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Utility Functions \n",
    "\n",
    "Importing from [helpers.py](../utils/helpers.py)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-26T16:18:16.790772Z",
     "start_time": "2021-01-26T16:18:16.414825Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "from utils.helpers import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Image Processing Functions\n",
    "\n",
    "Importing from [image_processing.py](../src/image_processing.py)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-26T16:18:18.679832Z",
     "start_time": "2021-01-26T16:18:18.528850Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "from src.image_processing import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Frames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-15T15:09:33.372312Z",
     "start_time": "2020-12-15T15:09:33.370239Z"
    }
   },
   "source": [
    "## Load all frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-26T16:19:40.368140Z",
     "start_time": "2021-01-26T16:19:34.971743Z"
    }
   },
   "outputs": [],
   "source": [
    "folders = [\"discarded_front(20201112_140127)\"]\n",
    "triplets_per_folder = {}\n",
    "\n",
    "for folder in folders:\n",
    "    triplets_per_folder[folder] = []\n",
    "    files = sorted(os.listdir(folder), key=lambda file: int(file.split(\"_\")[0]))\n",
    "    rgb_im_files = list(filter(lambda file: \"rgb\" in file, files))\n",
    "    depth_im_files = list(filter(lambda file: \"depth.png\" in file, files))\n",
    "    depth_arr_files = list(filter(lambda file: \"npy\" in file, files))\n",
    "    num_files = len(rgb_im_files)\n",
    "    \n",
    "    for i in range(num_files):\n",
    "        rgb_im_path = os.path.join(folder, rgb_im_files[i])\n",
    "        depth_im_path = os.path.join(folder, depth_im_files[i])\n",
    "        depth_arr_path = os.path.join(folder, depth_arr_files[i])\n",
    "\n",
    "        rgb_img = cv2.imread(rgb_im_path, cv2.IMREAD_COLOR)     # BGR image\n",
    "        depth_img = cv2.imread(depth_im_path, cv2.IMREAD_COLOR) # BGR image\n",
    "        depth_arr = np.load(depth_arr_path)\n",
    "        \n",
    "        triplets_per_folder[folder].append((rgb_img, depth_img, depth_arr))\n",
    "    \n",
    "print(\"Number of folders:\", len(triplets_per_folder))\n",
    "for i, k in enumerate(folders):\n",
    "    print(\"{}) Loaded {} frames from {}\".format(i, len(triplets_per_folder[k]), k))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-15T15:10:03.066139Z",
     "start_time": "2020-12-15T15:10:03.064146Z"
    }
   },
   "source": [
    "## Pick one frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-07T10:05:07.140666Z",
     "start_time": "2021-01-07T10:05:06.853152Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# folder_indices = list(range(8))\n",
    "# folder_idx = random.choice(folder_indices)\n",
    "# print(\"Folder choice:\", folder_idx)\n",
    "folder_idx = 0\n",
    "folder = folders[folder_idx]\n",
    "\n",
    "file_indices = list(range(0, 120))\n",
    "frame_idx = random.choice(file_indices)\n",
    "print(\"Frame choice:\", frame_idx)\n",
    "# frame_idx = 0\n",
    "\n",
    "print(\"Fetching frame: {} from folder: {}\".format(frame_idx+1, folder))\n",
    "rgb_img, depth_img, depth_arr = triplets_per_folder[folder][frame_idx]\n",
    "\n",
    "show_image_pairs(rgb_img, depth_img)\n",
    "\n",
    "# frame: 13 from folder: frames/20201112_133434 (3) -> \"Grayscale\", \"Sobel Vertical\", \"Threshold\", \"Hough Line\"\n",
    "# frame: 13 from folder: frames/20201112_140127 (6) -> \"Grayscale\", \"Sobel Vertical\", \"Spatial Threshold\", \"Threshold\", \"Hough Line\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create UI Elements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define UI Callback Functions\n",
    "\n",
    "Register a callback for configuration of image processing methods here if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-26T16:19:50.561104Z",
     "start_time": "2021-01-26T16:19:50.523191Z"
    }
   },
   "outputs": [],
   "source": [
    "def dilation_config(ksize=5):\n",
    "    return {\"ksize\": ksize}\n",
    "    \n",
    "def erosion_config(ksize=5):\n",
    "    return {\"ksize\": ksize}\n",
    "\n",
    "def opening_config(ksize=5):\n",
    "    return {\"ksize\": ksize}\n",
    "    \n",
    "def closing_config(ksize=5):\n",
    "    return {\"ksize\": ksize}\n",
    "\n",
    "def threshold_config(thresh=127, maxval=255, type=0):\n",
    "    return {\"thresh\": thresh, \"maxval\": maxval, \"type\": type}\n",
    "\n",
    "def adaptive_threshold_config(maxValue, adaptiveMethod, thresholdType, blockSize, C):\n",
    "    return {\"maxValue\": maxValue, \"adaptiveMethod\": adaptiveMethod, \"thresholdType\": thresholdType, \"blockSize\": blockSize, \"C\": C}\n",
    "\n",
    "def spatial_threshold_config(min_x=0, max_x=640, min_y=0, max_y=480):\n",
    "    return {\"range_x\": (min_x, max_x), \"range_y\": (min_y, max_y)}\n",
    "\n",
    "def avg_blur_config(ksize):\n",
    "    return {\"ksize\": ksize}\n",
    "\n",
    "def median_blur_config(ksize):\n",
    "    return {\"ksize\": ksize}\n",
    "\n",
    "def bilateral_filter_config(d, sigmaColor, sigmaSpace):\n",
    "    return {\"d\": d, \"sigmaColor\": sigmaColor, \"sigmaSpace\": sigmaSpace}\n",
    "\n",
    "def gaussian_blur_config(ksize=5, sigmaX=10):\n",
    "    return {\"ksize\": (ksize, ksize), \"sigmaX\": sigmaX}\n",
    "\n",
    "def laplacian_config(ksize=5):\n",
    "    return {\"ksize\": ksize}\n",
    "    \n",
    "def sobelv_config(ksize=5):\n",
    "    return {\"ksize\": ksize}\n",
    "    \n",
    "def sobelh_config(ksize=5):\n",
    "    return {\"ksize\": ksize}\n",
    "\n",
    "def canny_config(threshold1=100, threshold2=200, apertureSize=5):\n",
    "    return {\"threshold1\": threshold1, \n",
    "            \"threshold2\": threshold2, \n",
    "            \"apertureSize\": apertureSize}\n",
    "\n",
    "def config_shi_tomasi(blockSize=25, \n",
    "                      maxCorners=20, \n",
    "                      qualityLevel=0.75, \n",
    "                      minDistance=20):\n",
    "    return {\"blockSize\": blockSize, \n",
    "            \"maxCorners\": maxCorners, \n",
    "            \"qualityLevel\": qualityLevel, \n",
    "            \"minDistance\": minDistance}\n",
    "    \n",
    "def config_dsift(top_n=1000, step=1, size=5):\n",
    "    return {\"top_n\": top_n, \"step\": step, \"size\": size}\n",
    "\n",
    "def config_sift(peak_thresh=0, edge_thresh=10, norm_thresh=0, window_size=2):\n",
    "    return {\"peak_thresh\": peak_thresh, \n",
    "            \"edge_thresh\": edge_thresh, \n",
    "            \"norm_thresh\": norm_thresh, \n",
    "            \"window_size\": window_size}\n",
    "\n",
    "def hough_line_config(average=True,\n",
    "                      adaptive_thresh=True, # use half of the max vote as threshold\n",
    "                      num_lines=5,     # take num_lines top voted lines\n",
    "                      min_theta=0,     # minimum angles to accept a line\n",
    "                      max_theta=180,   # maximum angles to accept a line\n",
    "                      min_rho=-800, # minimum rho to accept a line\n",
    "                      max_rho=800,  # maximum rho to accept a line\n",
    "                      threshold=200,   # minimum votes required to accept a line\n",
    "                      theta_res=1,     # theta_res: 2 -> unit angle: 0.5\n",
    "                      min_distance=9,  # take lines separated with at least min_distance pixels\n",
    "                      min_angle=10):   # take lines separated with at least min_angle degrees\n",
    "    return {\"average\": average,\n",
    "            \"adaptive_thresh\": adaptive_thresh,\n",
    "            \"num_lines\": num_lines,\n",
    "            \"min_theta\": min_theta,\n",
    "            \"max_theta\": max_theta,\n",
    "            \"min_rho\": min_rho,\n",
    "            \"max_rho\": max_rho,\n",
    "            \"threshold\": threshold,\n",
    "            \"theta_res\": theta_res,   \n",
    "            \"min_distance\": min_distance,\n",
    "            \"min_angle\": min_angle}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Name-UI Mappings\n",
    "\n",
    "Bind names to the UI elements. Define new UI elements and name-UI element mappings here if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-26T16:19:51.652144Z",
     "start_time": "2021-01-26T16:19:51.618049Z"
    }
   },
   "outputs": [],
   "source": [
    "# Defining UI elements for configurations\n",
    "dilation_ui = lambda: interactive(dilation_config, ksize=(1,20))\n",
    "erosion_ui = lambda: interactive(erosion_config, ksize=(1,20))\n",
    "opening_ui = lambda: interactive(opening_config, ksize=(1,20))\n",
    "closing_ui = lambda: interactive(closing_config, ksize=(1,20))\n",
    "threshold_ui = lambda: interactive(threshold_config, thresh=(0.0,255.0,0.5), maxval=(0.0,255.0,0.5), \n",
    "                           type={\"Binary\": cv2.THRESH_BINARY,\n",
    "                                 \"Binary Inverted\": cv2.THRESH_BINARY_INV,\n",
    "                                 \"Trunctate\": cv2.THRESH_TRUNC,\n",
    "                                 \"To Zero\": cv2.THRESH_TOZERO,\n",
    "                                 \"To Zero Inverted\": cv2.THRESH_TOZERO_INV})\n",
    "adaptive_threshold_ui = lambda: interactive(adaptive_threshold_config, \n",
    "                                       maxValue=(0,255), \n",
    "                                       adaptiveMethod={\n",
    "                                           'Adaptive Gaussian Thresholding': cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "                                           'Adaptive Mean Thresholding': cv2.ADAPTIVE_THRESH_MEAN_C},\n",
    "                                       thresholdType={\"Binary\": cv2.THRESH_BINARY,\n",
    "                                                      \"Binary Inverted\": cv2.THRESH_BINARY_INV,\n",
    "                                                      \"Trunctate\": cv2.THRESH_TRUNC,\n",
    "                                                      \"To Zero\": cv2.THRESH_TOZERO,\n",
    "                                                      \"To Zero Inverted\": cv2.THRESH_TOZERO_INV},\n",
    "                                       blockSize=(0,20),\n",
    "                                       C=(0,20))\n",
    "spatial_threshold_ui = lambda: interactive(spatial_threshold_config, \n",
    "                                           min_x=(0,1000), max_x=(0,1000),\n",
    "                                           min_y=(0,1000), max_y=(0,1000))\n",
    "avg_blur_ui = lambda: interactive(avg_blur_config, ksize=(1,20))\n",
    "median_blur_ui = lambda: interactive(median_blur_config, ksize=(1,20))\n",
    "bilateral_filter_ui = lambda: interactive(bilateral_filter_config, d=(1,10), sigmaColor=(0,255), sigmaSpace=(0,200))\n",
    "gaussian_blur_ui = lambda: interactive(gaussian_blur_config, ksize=(1,20), sigmaX=(1,20))\n",
    "laplacian_ui = lambda: interactive(laplacian_config, ksize=(1,20))\n",
    "sobelv_ui = lambda: interactive(sobelv_config, ksize=(1,20))\n",
    "sobelh_ui = lambda: interactive(sobelh_config, ksize=(1,20))\n",
    "canny_ui = lambda: interactive(canny_config, threshold1=(0,500), threshold2=(0,500), apertureSize=(3, 7))\n",
    "shi_tomasi_ui = lambda: interactive(config_shi_tomasi, \n",
    "                                    blockSize=(0,100), \n",
    "                                    maxCorners=(0,200), \n",
    "                                    qualityLevel=(0.0,1.0,0.1),\n",
    "                                    minDistance=(0,200))\n",
    "dsift_ui = lambda: interactive(config_dsift, \n",
    "                               top_n=(0,200), \n",
    "                               step=(1,100), \n",
    "                               size=(1,100))\n",
    "sift_ui = lambda: interactive(config_sift, \n",
    "                              peak_thresh=(0,200), \n",
    "                              edge_thresh=(0,200), \n",
    "                              norm_thresh=(0,200), \n",
    "                              window_size=(1,100))\n",
    "hough_line_ui = lambda: interactive(hough_line_config,\n",
    "                                    num_lines=(1,500),\n",
    "                                    min_theta=(0,180),\n",
    "                                    max_theta=(0,180),\n",
    "                                    min_rho=(-800,800),\n",
    "                                    max_rho=(-800,800),\n",
    "                                    threshold=(0,100000),\n",
    "                                    theta_res=(1,5),\n",
    "                                    min_distance=(0,1000),\n",
    "                                    min_angle=(0,180))\n",
    "\n",
    "# Binding names to the configuration UI elements\n",
    "preproc_ui = {\n",
    "    \"Grayscale\": None,\n",
    "    \"Contrast\": None,\n",
    "    \"Dilation\": dilation_ui,\n",
    "    \"Erosion\": erosion_ui,\n",
    "    \"Opening\": opening_ui,\n",
    "    \"Closing\": closing_ui,\n",
    "    \"ROI Threshold\": None,\n",
    "    \"Threshold\": threshold_ui,\n",
    "    \"Adaptive Threshold\": adaptive_threshold_ui,\n",
    "    \"Spatial Threshold\": spatial_threshold_ui,\n",
    "    \"Average Blur\": avg_blur_ui,\n",
    "    \"Median Blur\": median_blur_ui,\n",
    "    \"Bilateral Filter\": bilateral_filter_ui,\n",
    "    \"Gaussian Blur\": gaussian_blur_ui,\n",
    "    \"Laplacian\": laplacian_ui,\n",
    "    \"Sobel Vertical\": sobelv_ui,\n",
    "    \"Sobel Horizontal\": sobelh_ui,\n",
    "}\n",
    "\n",
    "detect_ui = {\n",
    "    \"Canny Edges\": canny_ui,\n",
    "    \"Contour\": None,\n",
    "    \"Shi Tomasi\": shi_tomasi_ui,\n",
    "    \"Dense SIFT\": dsift_ui,\n",
    "    \"SIFT\": sift_ui,\n",
    "    \"Hough Line\": hough_line_ui,\n",
    "}\n",
    "\n",
    "ui_elements = {**preproc_ui, **detect_ui}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create New Experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select Methods "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-26T16:19:53.240898Z",
     "start_time": "2021-01-26T16:19:53.127204Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "style = {\n",
    "    'description_width': 'initial'\n",
    "}\n",
    "\n",
    "func_stack = []\n",
    "add_buttons = []\n",
    "log = Output(layout={'margin': '0px 50px 0px 50px', 'width': \"200px\"})\n",
    "\n",
    "for item in ui_elements:\n",
    "    button = Button(\n",
    "        description=item,\n",
    "        disabled=False,\n",
    "        button_style='success', # 'success', 'info', 'warning', 'danger' or ''\n",
    "    )\n",
    "    button.on_click(lambda e: push(func_stack, log, e))\n",
    "    add_buttons.append(button)\n",
    "\n",
    "pop_button = Button(\n",
    "    description=\"Pop\",\n",
    "    disabled=False,\n",
    "    button_style='danger', # 'success', 'info', 'warning', 'danger' or ''\n",
    ")\n",
    "pop_button.on_click(lambda _: pop(func_stack, log))\n",
    "    \n",
    "menu1 = HBox([VBox(add_buttons), log, pop_button])\n",
    "\n",
    "display(menu1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure Selected Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-26T16:20:12.176828Z",
     "start_time": "2021-01-26T16:20:12.112772Z"
    }
   },
   "outputs": [],
   "source": [
    "ui_instances = []\n",
    "for i, k in enumerate(func_stack):\n",
    "    if ui_elements[k]:\n",
    "        print(\"{} {}:\".format(i, k))\n",
    "        ui_instance = ui_elements[k]()\n",
    "        display(ui_instance)\n",
    "        ui_instances.append(ui_instance)\n",
    "    else:\n",
    "        ui_instances.append(None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply Configured Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-21T17:25:14.511623Z",
     "start_time": "2020-12-21T17:25:14.494390Z"
    }
   },
   "outputs": [],
   "source": [
    "input_image = depth_img.copy() # rgb_img\n",
    "roi_config = {}\n",
    "NUM_CORNERS = 5\n",
    "\n",
    "idx = -1\n",
    "try:\n",
    "    idx = func_stack.index(\"ROI Threshold\")\n",
    "except Exception:\n",
    "    print(\"[Info]: ROI Threshold is not selected.\")\n",
    "\n",
    "if idx >= 0:\n",
    "    matplotlib.use(\"Qt5Agg\")\n",
    "    roi_config[\"roi_corners\"] = set_roi(input_image, NUM_CORNERS)\n",
    "    print(\"[Info]: ROI Threshold is configured.\")\n",
    "    %matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-21T17:25:14.937246Z",
     "start_time": "2020-12-21T17:25:14.924200Z"
    }
   },
   "outputs": [],
   "source": [
    "pprint(roi_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-21T17:30:05.277297Z",
     "start_time": "2020-12-21T17:30:04.554538Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "config_stack = []\n",
    "# Update internal state\n",
    "for ui_instance in ui_instances:\n",
    "    config = {}\n",
    "    if ui_instance:\n",
    "        config = ui_instance.result\n",
    "    config_stack.append(config)\n",
    "if roi_config:\n",
    "    config_stack[idx] = roi_config\n",
    "\n",
    "input_image = depth_img.copy() # rgb_img\n",
    "output = apply_functions(input_image.copy(), func_stack, config_stack)\n",
    "# show_shapes(input_image.copy(), output, shapeIdx=0, cmap=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Store Current Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-12T17:21:47.189657Z",
     "start_time": "2020-12-12T17:21:47.173260Z"
    }
   },
   "outputs": [],
   "source": [
    "text = Text(\n",
    "    value='exp.json',\n",
    "    placeholder='Enter a filename',\n",
    "    description='Filename:',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "\n",
    "button = Button(\n",
    "    description='Store',\n",
    "    disabled=False,\n",
    "    button_style='success', # 'success', 'info', 'warning', 'danger' or ''\n",
    ")\n",
    "\n",
    "mini_form = HBox([text, button])\n",
    "\n",
    "button.on_click(lambda _: save_config(text.value, func_stack, config_stack))\n",
    "\n",
    "display(mini_form)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Previous Experiment from File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-12T18:16:12.381753Z",
     "start_time": "2020-12-12T18:16:12.371096Z"
    }
   },
   "outputs": [],
   "source": [
    "# TODO: Ability to continue with loaded experiment\n",
    "config_stack = []\n",
    "uploader_ui = FileUpload(\n",
    "    accept='.json', # Accepted file extension e.g. '.txt', '.pdf', 'image/*', 'image/*,.pdf'\n",
    "    multiple=False  # True to accept multiple files upload else False\n",
    ")\n",
    "\n",
    "uploader_ui.observe(lambda _: load_config(*uploader_ui.data, func_stack, config_stack), names='_counter')\n",
    "\n",
    "display(uploader_ui)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-12T18:19:45.258904Z",
     "start_time": "2020-12-12T18:19:45.246509Z"
    }
   },
   "outputs": [],
   "source": [
    "exps = []\n",
    "\n",
    "def load_exp(json_contents, exps):\n",
    "    for json_content in json_contents:\n",
    "        exp = json.loads(json_content)\n",
    "        exps.append((exp[\"func_stack\"], exp[\"config_stack\"]))\n",
    "    \n",
    "\n",
    "uploader_ui = FileUpload(\n",
    "    accept='.json', # Accepted file extension e.g. '.txt', '.pdf', 'image/*', 'image/*,.pdf'\n",
    "    multiple=True  # True to accept multiple files upload else False\n",
    ")\n",
    "\n",
    "uploader_ui.observe(lambda _: load_exp(uploader_ui.data, exps), names='_counter')\n",
    "\n",
    "display(uploader_ui)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-12T18:19:52.422028Z",
     "start_time": "2020-12-12T18:19:51.616118Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "input_image = depth_img # rgb_img\n",
    "results = []\n",
    "\n",
    "for exp in exps:\n",
    "    result = apply_functions(input_image, *exp)\n",
    "    results.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-12T18:19:55.052107Z",
     "start_time": "2020-12-12T18:19:54.910730Z"
    }
   },
   "outputs": [],
   "source": [
    "show_shapes(input_image, results[0], shapeIdx=0, cmap=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-12T18:20:41.348937Z",
     "start_time": "2020-12-12T18:20:41.153373Z"
    }
   },
   "outputs": [],
   "source": [
    "show_shapes(rgb_img.copy(), results[0], shapeIdx=0, cmap=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-12T18:17:22.536555Z",
     "start_time": "2020-12-12T18:17:22.528875Z"
    }
   },
   "outputs": [],
   "source": [
    "# Merging Canny detector result with Hough line detector result\n",
    "horizontal = results[0]\n",
    "vertical = convert_coord2mask(horizontal.shape, results[1][0])\n",
    "merged = horizontal | vertical\n",
    "show_image(merged, cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-30T12:30:37.997825Z",
     "start_time": "2020-11-30T12:30:37.979214Z"
    }
   },
   "source": [
    "# Aside: Experimental"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-07T10:05:12.972503Z",
     "start_time": "2021-01-07T10:05:12.957513Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tmp1 = create_template(size=20, position=1)\n",
    "# ...\n",
    "templates = [tmp1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-07T10:05:15.707252Z",
     "start_time": "2021-01-07T10:05:14.791581Z"
    }
   },
   "outputs": [],
   "source": [
    "# Fit a line to inlier detections\n",
    "pixel_coords = []\n",
    "points = []\n",
    "\n",
    "for template in templates:\n",
    "    pixels, corners, outliers = apply_template_matching(depth_arr.astype(np.float32), \n",
    "                                                        template,\n",
    "                                                        y_step=25,\n",
    "                                                        n_contours=200,\n",
    "                                                        fit_type=\"line\",\n",
    "                                                        verbose=1)\n",
    "    pixel_coords.append(pixels)\n",
    "    points.append((corners, outliers))\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(depth_img)\n",
    "for corners, outliers in points:\n",
    "    plt.scatter(corners[:,1], corners[:,0], color=\"black\", marker=\"o\")\n",
    "    plt.scatter(outliers[:,1], outliers[:,0], color=\"purple\", marker=\"^\")\n",
    "plt.show()\n",
    "\n",
    "mask = np.zeros(depth_arr.shape, dtype=np.bool)\n",
    "for p in pixel_coords:\n",
    "    tmp = convert_coord2mask(depth_arr.shape, p)\n",
    "    mask = mask | tmp\n",
    "    \n",
    "show_overlay(rgb_img, mask)\n",
    "show_overlay(depth_img, mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-07T10:05:23.707371Z",
     "start_time": "2021-01-07T10:05:22.815911Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Fit a curve (2nd degree polynomial) to inlier detections\n",
    "pixel_coords = []\n",
    "points = []\n",
    "\n",
    "for template in templates:\n",
    "    pixels, corners, outliers = apply_template_matching(depth_arr.astype(np.float32), \n",
    "                                                        template,\n",
    "                                                        y_step=25,\n",
    "                                                        n_contours=200,\n",
    "                                                        fit_type=\"curve\",\n",
    "                                                        verbose=1)\n",
    "    pixel_coords.append(pixels)\n",
    "    points.append((corners, outliers))\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(depth_img)\n",
    "for corners, outliers in points:\n",
    "    plt.scatter(corners[:,1], corners[:,0], color=\"black\", marker=\"o\")\n",
    "    plt.scatter(outliers[:,1], outliers[:,0], color=\"purple\", marker=\"^\")\n",
    "plt.show()\n",
    "\n",
    "mask = np.zeros(depth_arr.shape, dtype=np.bool)\n",
    "for p in pixel_coords:\n",
    "    tmp = convert_coord2mask(depth_arr.shape, p)\n",
    "    mask = mask | tmp\n",
    "    \n",
    "show_overlay(rgb_img, mask)\n",
    "show_overlay(depth_img, mask);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-04T14:48:53.247332Z",
     "start_time": "2021-01-04T14:48:52.976810Z"
    }
   },
   "outputs": [],
   "source": [
    "size = 30\n",
    "mask = create_template(size)\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(mask, cmap=\"gray\", extent=[0, mask.shape[1], mask.shape[0], 0])\n",
    "plt.xticks(np.arange(mask.shape[1]+1))\n",
    "plt.yticks(np.arange(mask.shape[0]+1))\n",
    "plt.show()\n",
    "# np.save(f\"{size}x{size}\", mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-20T20:20:12.031402Z",
     "start_time": "2020-12-20T20:20:11.587985Z"
    }
   },
   "outputs": [],
   "source": [
    "contours = find_contours(output, 0.8)\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(output)\n",
    "for contour in contours:\n",
    "    plt.plot(contour[:, 1], contour[:, 0], linewidth=2)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "convex_hull = convex_hull_image(output)\n",
    "show_image(convex_hull, cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-30T11:58:51.504898Z",
     "start_time": "2020-12-30T11:58:51.292991Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "choice = np.random.randint(0, 640, 5)\n",
    "print(\"Choice:\", choice)\n",
    "\n",
    "arr = np.rot90(depth_arr, axes=(1,0))\n",
    "\n",
    "X = np.arange(479, -1, -1)\n",
    "y = np.divide(1, arr, out=np.zeros_like(arr), where=arr!=0)\n",
    "\n",
    "# m = -0.0027798553391156096\n",
    "# b = 1.3734837318132027\n",
    "model = LinearRegression()\n",
    "m = 0\n",
    "b = 0\n",
    "for i, y_vec in enumerate(y):\n",
    "    model.fit(X.reshape(-1,1), y_vec.reshape(-1,1))    \n",
    "    m += model.coef_.item()\n",
    "    b += model.intercept_.item()\n",
    "\n",
    "m /= i\n",
    "b /= i\n",
    "print(\"m:\", m, \"b:\", b)\n",
    "for y_vec in y[choice]:\n",
    "    plt.plot(X, y_vec)\n",
    "\n",
    "y_pred = m * X + b\n",
    "plt.plot(X, y_pred, color=\"black\", linestyle=\"--\", linewidth=2)\n",
    "plt.xlim(480, 0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-30T11:58:55.367978Z",
     "start_time": "2020-12-30T11:58:54.374664Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "contour_masks = []\n",
    "start_depth = 0.8\n",
    "step = 0.1\n",
    "width = 0.02\n",
    "n_contours = 10\n",
    "dy = estimate_dy(start_depth, width) # dy to be kept constant\n",
    "for i in range(n_contours):\n",
    "    min_depth = start_depth + (step * i)\n",
    "    ddepth = estimate_ddepth(min_depth, dy)\n",
    "    print(\"ddepth:\", ddepth)\n",
    "    max_depth = min_depth + ddepth\n",
    "    print(f\"Contour-{i}: ({min_depth:.2f}-{max_depth:.2f})\")\n",
    "    contour_mask = (depth_arr >= min_depth) & (depth_arr <= max_depth)\n",
    "    show_image(contour_mask, cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-28T17:55:43.030170Z",
     "start_time": "2020-12-28T17:55:33.748Z"
    }
   },
   "outputs": [],
   "source": [
    "# Generate sample data\n",
    "y = np.random.randint(0, 480, (200, 1))\n",
    "x1 = np.random.randint(0, 250, (10, 1))\n",
    "x2 = np.random.randint(250, 450, (180, 1))\n",
    "x3 = np.random.randint(450, 640, (10, 1))\n",
    "x = np.vstack((x1,x2,x3))\n",
    "\n",
    "# Cluster corners horizontally\n",
    "corners = np.hstack((y,x))\n",
    "inlier_corners = cluster_along_x(corners, verbose=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-04T11:30:02.841917Z",
     "start_time": "2021-01-04T11:30:02.513877Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "p_slope = {\"m\": 1, \"b\": 160, \"type\": \"slope\"}\n",
    "p_hough = {\"theta\": np.pi/2, \"rho\": 120, \"type\": \"hough\"}\n",
    "y = np.random.randint(0,480,(10,1))\n",
    "x = np.random.randint(0,640,(10,1))\n",
    "corners = np.stack((y,x), axis=2)\n",
    "cv_corners = np.stack((x,y), axis=2)\n",
    "vp = cv2.fitLine(cv_corners, cv2.DIST_HUBER, 0, 0.01, 0.01).ravel()\n",
    "p_sym = {\"v\": vp[0:2], \"p\": vp[2:4], \"type\": \"symmetric\"}\n",
    "line_pixels1 = compute_visible_pixels(depth_arr.shape, p_slope)\n",
    "line_pixels2 = compute_visible_pixels(depth_arr.shape, p_sym)\n",
    "line_pixels4 = compute_visible_pixels(depth_arr.shape, p_hough)\n",
    "line_mask1 = convert_coord2mask(depth_arr.shape, line_pixels1)\n",
    "line_mask2 = convert_coord2mask(depth_arr.shape, line_pixels2)\n",
    "line_mask4 = convert_coord2mask(depth_arr.shape, line_pixels4)\n",
    "show_image(line_mask1, cmap=\"gray\")\n",
    "show_image(line_mask2, cmap=\"gray\")\n",
    "show_image(line_mask4, cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-14T12:36:43.914397Z",
     "start_time": "2020-12-14T12:36:39.053889Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Interactive Hough line visualization\n",
    "def draw_line(rho=240, theta=45):\n",
    "    shape = (480, 640)\n",
    "    top = 0\n",
    "    bottom = shape[0] - 1\n",
    "    left = 0\n",
    "    right = shape[1] - 1\n",
    "    theta = np.deg2rad(theta)\n",
    "    \n",
    "    # When theta is multiples of pi/2, set endpoints manually.\n",
    "    if theta == np.pi/2:\n",
    "        p1 = np.array([rho, left])\n",
    "        p2 = np.array([rho, right])\n",
    "    # Otherwise, use formula\n",
    "    else:\n",
    "        p1 = np.array([top, rho/np.cos(theta)])\n",
    "        p2 = np.array([bottom, (rho-bottom*np.sin(theta))/np.cos(theta)])\n",
    "\n",
    "    print(\"sin(theta)==0:\", np.isclose(0, np.sin(theta)))\n",
    "    print(\"cos(theta)==0:\", np.isclose(0, np.cos(theta)))\n",
    "    print(\"Start:\", p1)\n",
    "    print(\"End:\", p2)\n",
    "\n",
    "    pixel_coords = line(*np.rint(p1).astype(np.int32), *np.rint(p2).astype(np.int32))\n",
    "    \n",
    "    # Merge coordinates in a matrix\n",
    "    pixel_coords = np.stack(pixel_coords, axis=1)\n",
    "    \n",
    "    # Take coordinates in the 1st quadrant\n",
    "    pixel_coords = pixel_coords[np.min(pixel_coords, axis=1)>=0]\n",
    "    \n",
    "    # Take coordinates in the visible region\n",
    "    visible = (pixel_coords[:,0] < shape[0]) & (pixel_coords[:,1] < shape[1])\n",
    "    pixel_coords = pixel_coords[visible]\n",
    "    \n",
    "    line_image = np.zeros(shape, dtype=np.uint8)\n",
    "    line_image[pixel_coords[:, 0], pixel_coords[:, 1]] = 255\n",
    "    plt.figure(figsize = (10, 10))\n",
    "    plt.imshow(line_image)\n",
    "    \n",
    "interactive(draw_line, rho=(0, 750), theta=(0, 180))\n",
    "\n",
    "# for angle in range(0, 181, 5):\n",
    "#     draw_line(rho=240, theta=angle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-12T21:15:50.185644Z",
     "start_time": "2020-12-12T21:15:49.961190Z"
    }
   },
   "outputs": [],
   "source": [
    "# Draw a convex polygon enclosing a set of points\n",
    "orig = depth_img\n",
    "copy1 = orig.copy()\n",
    "copy2 = orig.copy()\n",
    "\n",
    "mask1 = np.zeros(copy1.shape, dtype=np.uint8)\n",
    "mask2 = np.zeros(copy2.shape, dtype=np.uint8)\n",
    "roi_corners = np.array([[(0, 0), (100,100), (50,0)]], dtype=np.int32)\n",
    "C = copy.shape[2]\n",
    "white = (255,) * C\n",
    "cv2.fillPoly(mask1, roi_corners, color=white)\n",
    "cv2.fillConvexPoly(mask2, roi_corners, color=white)\n",
    "# from Masterfool: use cv2.fillConvexPoly if you know it's convex\n",
    "image1 = cv2.bitwise_and(copy1, mask1)\n",
    "image2 = cv2.bitwise_and(copy2, mask2)\n",
    "\n",
    "show_image(image1)\n",
    "show_image(image2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inpainting\n",
    "target = depth_img.copy()\n",
    "mask = convert_grayscale(target, visualize=False)\n",
    "mask = apply_threshold(mask, visualize=False, thresh=0, maxval=1, type=1)\n",
    "\n",
    "show_image(mask, cmap=\"gray\")\n",
    "\n",
    "inpainted = cv2.inpaint(target, mask, inpaintRadius=3, flags=cv2.INPAINT_TELEA)\n",
    "\n",
    "show_image(depth_img)\n",
    "show_image(inpainted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Help"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coordinate Conventions of NumPy and OpenCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us consider an arbitrary point P in the OpenCV coordinate system whose coordinates are (x, y). The same point in the NumPy image coordinate system is given by the coordinates (c, r).\n",
    "\n",
    "Assume that we need to manipulate the image at point P and that the image is stored in the NumPy array img. OpenCV functions typically expect us to provide the coordinate information in the order **(x, y)** for its image manipulation functions. However, to access the element at point P using NumPy, we need to do **img[r, c]**.\n",
    "\n",
    "### OpenCV Coordinates\n",
    "---\n",
    "![1st](figures/opencv.png \"OpenCV Coordinates\")\n",
    "\n",
    "### NumPy Coordinates\n",
    "---\n",
    "![2nd](figures/numpy.png \"NumPy Coordinates\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cv2.COLOR_XXX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[cv2.COLOR_XXX](https://vovkos.github.io/doxyrest-showcase/opencv/sphinx_rtd_theme/enum_cv_ColorConversionCodes.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-30T13:30:07.127021Z",
     "start_time": "2020-11-30T13:30:07.125039Z"
    }
   },
   "source": [
    "## cv2.THRESH_XXX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-30T13:14:14.696849Z",
     "start_time": "2020-11-30T13:14:14.693658Z"
    }
   },
   "source": [
    "[Thresholding](https://opencv-python-tutroals.readthedocs.io/en/latest/py_tutorials/py_imgproc/py_thresholding/py_thresholding.html)\n",
    "\n",
    "[cv2.THRESH_XXX](https://vovkos.github.io/doxyrest-showcase/opencv/sphinx_rtd_theme/enum_cv_ThresholdTypes.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cv2.cvtColor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-30T13:26:28.319261Z",
     "start_time": "2020-11-30T13:26:28.316324Z"
    }
   },
   "outputs": [],
   "source": [
    "help(cv2.cvtColor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cv2.equalizeHist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-26T18:46:03.624884Z",
     "start_time": "2020-11-26T18:46:03.621940Z"
    }
   },
   "outputs": [],
   "source": [
    "help(cv2.equalizeHist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cv2.threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-30T17:50:55.921843Z",
     "start_time": "2020-11-30T17:50:55.918297Z"
    }
   },
   "outputs": [],
   "source": [
    "help(cv2.threshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cv2.adaptiveThreshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-01T10:13:02.746401Z",
     "start_time": "2020-12-01T10:13:02.742866Z"
    }
   },
   "outputs": [],
   "source": [
    "help(cv2.adaptiveThreshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cv2.filter2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-26T18:46:04.136057Z",
     "start_time": "2020-11-26T18:46:04.132968Z"
    }
   },
   "outputs": [],
   "source": [
    "help(cv2.filter2D)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cv2.blur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-26T18:46:04.728688Z",
     "start_time": "2020-11-26T18:46:04.724068Z"
    }
   },
   "outputs": [],
   "source": [
    "help(cv2.blur)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cv2.medianBlur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-26T18:46:05.107402Z",
     "start_time": "2020-11-26T18:46:05.103901Z"
    }
   },
   "outputs": [],
   "source": [
    "help(cv2.medianBlur)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cv2.bilateralFilter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-26T18:46:05.920885Z",
     "start_time": "2020-11-26T18:46:05.917720Z"
    }
   },
   "outputs": [],
   "source": [
    "help(cv2.bilateralFilter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cv2.GaussianBlur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-26T18:46:06.693074Z",
     "start_time": "2020-11-26T18:46:06.690346Z"
    }
   },
   "outputs": [],
   "source": [
    "help(cv2.GaussianBlur)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cv2.Sobel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-02T13:27:20.186404Z",
     "start_time": "2020-12-02T13:27:20.183304Z"
    }
   },
   "outputs": [],
   "source": [
    "help(cv2.Sobel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cv2.Laplacian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-01T16:00:51.708924Z",
     "start_time": "2020-12-01T16:00:51.705966Z"
    }
   },
   "outputs": [],
   "source": [
    "help(cv2.Laplacian)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cv2.Canny"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All pixels having intensity between 1st and 2nd thresholds are flagged as weak and the Hysteresis mechanism will identify the ones that could be considered as strong and the ones that are considered as non-relevant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-07T11:40:25.916348Z",
     "start_time": "2020-12-07T11:40:25.913034Z"
    }
   },
   "outputs": [],
   "source": [
    "help(cv2.Canny)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cv2.findContours"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Convex Hull](https://opencv-python-tutroals.readthedocs.io/en/latest/py_tutorials/py_imgproc/py_contours/py_contour_features/py_contour_features.html#convex-hull)\n",
    "\n",
    "[Fitting a Line](https://opencv-python-tutroals.readthedocs.io/en/latest/py_tutorials/py_imgproc/py_contours/py_contour_features/py_contour_features.html#fitting-a-line)\n",
    "\n",
    "[Mask and Pixel Points](https://opencv-python-tutroals.readthedocs.io/en/latest/py_tutorials/py_imgproc/py_contours/py_contour_properties/py_contour_properties.html#mask-and-pixel-points)\n",
    "\n",
    "[Match Shapes](https://opencv-python-tutroals.readthedocs.io/en/latest/py_tutorials/py_imgproc/py_contours/py_contours_more_functions/py_contours_more_functions.html#match-shapes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-01T11:29:52.769030Z",
     "start_time": "2020-12-01T11:29:52.766270Z"
    }
   },
   "outputs": [],
   "source": [
    "help(cv2.findContours)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cv2.HoughLines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* If the line is passing below the origin, it will have a positive rho and an angle less than 180. If it is going above the origin, instead of taking an angle greater than 180, the angle is taken less than 180, and rho is taken negative. \n",
    "* Any vertical line will have 0 degree and horizontal lines will have 90 degree.\n",
    "\n",
    "[Hough Transform Theory](https://opencv-python-tutroals.readthedocs.io/en/latest/py_tutorials/py_imgproc/py_houghlines/py_houghlines.html#theory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-13T20:36:47.593290Z",
     "start_time": "2020-12-13T20:36:47.590235Z"
    }
   },
   "outputs": [],
   "source": [
    "help(cv2.HoughLines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cv2.inpaint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-07T12:22:59.303054Z",
     "start_time": "2020-12-07T12:22:59.276735Z"
    }
   },
   "outputs": [],
   "source": [
    "help(cv2.inpaint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## skimage.filters.farid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-12T20:42:00.289439Z",
     "start_time": "2020-12-12T20:42:00.285846Z"
    }
   },
   "outputs": [],
   "source": [
    "help(filters.farid)\n",
    "help(filters.farid_v)\n",
    "help(filters.farid_h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## skimage.filters.roberts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-12T20:40:43.505121Z",
     "start_time": "2020-12-12T20:40:43.498425Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "help(filters.roberts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cv2.goodFeaturesToTrack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-21T16:27:19.949790Z",
     "start_time": "2020-12-21T16:27:19.874767Z"
    }
   },
   "outputs": [],
   "source": [
    "help(cv2.goodFeaturesToTrack)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cyvlfeat.sift.sift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-16T19:04:59.918320Z",
     "start_time": "2020-12-16T19:04:59.905155Z"
    }
   },
   "outputs": [],
   "source": [
    "help(cyvlfeat.sift.sift)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cyvlfeat.sift.dsift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-16T19:05:08.181465Z",
     "start_time": "2020-12-16T19:05:08.167728Z"
    }
   },
   "outputs": [],
   "source": [
    "help(cyvlfeat.sift.dsift)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Torchvision Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Available Model List](https://pytorch.org/docs/stable/torchvision/models.html)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "705px",
    "left": "94px",
    "top": "110px",
    "width": "266px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "711px",
    "left": "1017px",
    "right": "20px",
    "top": "230px",
    "width": "750px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
